{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc082433",
   "metadata": {},
   "source": [
    "# LangGraph 101\n",
    "\n",
    "[LLMs](https://python.langchain.com/docs/concepts/chat_models/) make it possible to embed intelligence into a new class of applications. [LangGraph](https://langchain-ai.github.io/langgraph/) is a framework to help build applications with LLMs. Here, we will overview the basics of LangGraph, explain its benefits, show how to use it to build workflows / agents, and show how it works with [LangChain](https://www.langchain.com/) / [LangSmith](https://docs.smith.langchain.com/).\n",
    "\n",
    "![ecosystem](./img/ecosystem.png)\n",
    "\n",
    "## Chat models\n",
    "\n",
    "[Chat models](https://python.langchain.com/docs/concepts/chat_models/) are the foundation of LLM applications. They are typically accessed through a chat interface that takes a list of [messages](https://python.langchain.com/docs/concepts/messages/) as input and returns a [message](https://python.langchain.com/docs/concepts/messages/) as output. LangChain provides [a standardized interface for chat models](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html), making it easy to [access many different providers](https://python.langchain.com/docs/integrations/chat/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecc2b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ee8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc1ba8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "llm.invoke(\n",
      "    input: \u001b[33m'LanguageModelInput'\u001b[39m,\n",
      "    config: \u001b[33m'Optional[RunnableConfig]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    *,\n",
      "    stop: \u001b[33m'Optional[list[str]]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    **kwargs: \u001b[33m'Any'\u001b[39m,\n",
      ") -> \u001b[33m'BaseMessage'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Transform a single input into an output.\n",
      "\n",
      "Args:\n",
      "    input: The input to the Runnable.\n",
      "    config: A config to use when invoking the Runnable.\n",
      "       The config supports standard keys like 'tags', 'metadata' for tracing\n",
      "       purposes, 'max_concurrency' for controlling how much work to do\n",
      "       in parallel, and other keys. Please refer to the RunnableConfig\n",
      "       for more details.\n",
      "\n",
      "Returns:\n",
      "    The output of the Runnable.\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "    @override\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m invoke(\n",
      "        self,\n",
      "        input: LanguageModelInput,\n",
      "        config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        *,\n",
      "        stop: Optional[list[str]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        **kwargs: Any,\n",
      "    ) -> BaseMessage:\n",
      "        config = ensure_config(config)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n",
      "            \u001b[33m\"ChatGeneration\"\u001b[39m,\n",
      "            self.generate_prompt(\n",
      "                [self._convert_input(input)],\n",
      "                stop=stop,\n",
      "                callbacks=config.get(\u001b[33m\"callbacks\"\u001b[39m),\n",
      "                tags=config.get(\u001b[33m\"tags\"\u001b[39m),\n",
      "                metadata=config.get(\u001b[33m\"metadata\"\u001b[39m),\n",
      "                run_name=config.get(\u001b[33m\"run_name\"\u001b[39m),\n",
      "                run_id=config.pop(\u001b[33m\"run_id\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n",
      "                **kwargs,\n",
      "            ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n",
      "        ).message\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\cikeg\\onedrive\\desktop\\desktop documents\\code\\ai agents\\langraph-agents-from-scratch\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "llm.invoke??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50777b0b",
   "metadata": {},
   "source": [
    "## Running the model\n",
    "\n",
    "The `init_chat_model` interface provides [standardized](https://python.langchain.com/docs/concepts/runnables/) methods for using chat models, which include:\n",
    "- `invoke()`: A single input is transformed into an output.\n",
    "- `stream()`: Outputs are [streamed](https://python.langchain.com/docs/concepts/streaming/#stream-and-astream) as they are produced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a28159d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ''' \n",
    "What is an agent?, and how does it differ from a standard LLM? \n",
    "How accurate is it to say agents are just two or more llms solving problems together and evaluating each other.\n",
    "\n",
    "'''\n",
    "\n",
    "result = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41137023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1d00eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Great questions! Let’s break them down:                                                                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                               <span style=\"font-weight: bold\">1. What is an agent?</span>                                                \n",
       "\n",
       "In the context of AI and LLMs, an <span style=\"font-weight: bold\">agent</span> is a system that can <span style=\"font-weight: bold\">autonomously perceive, reason, and act</span> in an          \n",
       "environment to achieve specific goals. In practice, an \"agent\" built on top of an LLM (like GPT-4) is typically a  \n",
       "software entity that:                                                                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Receives tasks or goals</span> (e.g., \"Book me a flight to Paris\").                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Plans actions</span> (e.g., search for flights, compare prices).                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Interacts with tools or APIs</span> (e.g., web browsers, databases, email).                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Makes decisions</span> based on feedback or results.                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Iterates</span> until the goal is achieved or a stopping condition is met.                                             \n",
       "\n",
       "<span style=\"font-weight: bold\">Key point:</span> An agent is not just a model—it’s a system that uses models (often LLMs) as components to reason, plan, \n",
       "and act.                                                                                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                    <span style=\"font-weight: bold\">2. How does it differ from a standard LLM?</span>                                     \n",
       "\n",
       "A <span style=\"font-weight: bold\">standard LLM</span> (like GPT-4, Claude, etc.) is a <span style=\"font-weight: bold\">stateless text generator</span>: you give it a prompt, it gives you a      \n",
       "response. It doesn’t remember past interactions (unless you include them in the prompt), and it doesn’t take       \n",
       "actions in the world.                                                                                              \n",
       "\n",
       "<span style=\"font-weight: bold\">An agent, by contrast:</span>                                                                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Has memory/state:</span> It can remember previous steps, results, or context.                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Can take actions:</span> It can call APIs, use tools, browse the web, etc.                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Can plan and iterate:</span> It can break down tasks, try different approaches, and adapt based on feedback.           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">May use multiple models or tools:</span> It can coordinate between different LLMs, APIs, or software components.       \n",
       "\n",
       "<span style=\"font-weight: bold\">Summary:</span>                                                                                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">LLM:</span> Text-in, text-out, no memory, no actions.                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Agent:</span> Goal-in, actions-out, with memory, planning, and tool use.                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "             <span style=\"font-weight: bold\">3. Are agents just two or more LLMs solving problems together and evaluating each other?</span>              \n",
       "\n",
       "<span style=\"font-weight: bold\">Not exactly.</span>                                                                                                       \n",
       "While some agent architectures use multiple LLMs (e.g., one to generate solutions, another to critique), <span style=\"font-weight: bold\">the core </span> \n",
       "<span style=\"font-weight: bold\">idea of an agent is broader</span>:                                                                                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Agents can use a single LLM</span> (with code to manage memory, planning, and tool use).                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Agents can use multiple LLMs</span> (for self-critique, debate, or specialized tasks).                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Agents can use non-LLM tools</span> (APIs, databases, calculators, etc.).                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Agents are defined by their autonomy and ability to act</span>, not just by having multiple LLMs.                      \n",
       "\n",
       "<span style=\"font-weight: bold\">So:</span>                                                                                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>It’s <span style=\"font-weight: bold\">inaccurate</span> to say agents are <span style=\"font-style: italic\">just</span> two or more LLMs solving and evaluating together.                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>That’s <span style=\"font-style: italic\">one possible architecture</span>, but not the definition of an agent.                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                   <span style=\"font-weight: bold\">Summary Table</span>                                                   \n",
       "\n",
       "                                                               \n",
       " <span style=\"font-weight: bold\"> Feature       </span> <span style=\"font-weight: bold\"> Standard LLM    </span> <span style=\"font-weight: bold\"> Agent (LLM-based)         </span> \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       "  Memory          No (stateless)    Yes (stateful)             \n",
       "  Planning        No                Yes                        \n",
       "  Tool Use        No                Yes                        \n",
       "  Autonomy        No                Yes                        \n",
       "  Multiple LLMs   Not required      Optional                   \n",
       "  Example         ChatGPT, Claude   Auto-GPT, LangChain Agent  \n",
       "                                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "<span style=\"font-weight: bold\">In short:</span>                                                                                                          \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>An agent is an autonomous system that can plan, act, and use tools (often powered by LLMs).                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>It’s not just multiple LLMs working together, though that can be part of an agent’s design.                     \n",
       "\n",
       "Let me know if you want examples or more technical details!                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Great questions! Let’s break them down:                                                                            \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                               \u001b[1m1. \u001b[0m\u001b[1mWhat is an agent?\u001b[0m                                                \n",
       "\n",
       "In the context of AI and LLMs, an \u001b[1magent\u001b[0m is a system that can \u001b[1mautonomously perceive, reason, and act\u001b[0m in an          \n",
       "environment to achieve specific goals. In practice, an \"agent\" built on top of an LLM (like GPT-4) is typically a  \n",
       "software entity that:                                                                                              \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mReceives tasks or goals\u001b[0m (e.g., \"Book me a flight to Paris\").                                                    \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mPlans actions\u001b[0m (e.g., search for flights, compare prices).                                                       \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mInteracts with tools or APIs\u001b[0m (e.g., web browsers, databases, email).                                            \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMakes decisions\u001b[0m based on feedback or results.                                                                   \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mIterates\u001b[0m until the goal is achieved or a stopping condition is met.                                             \n",
       "\n",
       "\u001b[1mKey point:\u001b[0m An agent is not just a model—it’s a system that uses models (often LLMs) as components to reason, plan, \n",
       "and act.                                                                                                           \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                    \u001b[1m2. \u001b[0m\u001b[1mHow does it differ from a standard LLM?\u001b[0m                                     \n",
       "\n",
       "A \u001b[1mstandard LLM\u001b[0m (like GPT-4, Claude, etc.) is a \u001b[1mstateless text generator\u001b[0m: you give it a prompt, it gives you a      \n",
       "response. It doesn’t remember past interactions (unless you include them in the prompt), and it doesn’t take       \n",
       "actions in the world.                                                                                              \n",
       "\n",
       "\u001b[1mAn agent, by contrast:\u001b[0m                                                                                             \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mHas memory/state:\u001b[0m It can remember previous steps, results, or context.                                          \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mCan take actions:\u001b[0m It can call APIs, use tools, browse the web, etc.                                             \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mCan plan and iterate:\u001b[0m It can break down tasks, try different approaches, and adapt based on feedback.           \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMay use multiple models or tools:\u001b[0m It can coordinate between different LLMs, APIs, or software components.       \n",
       "\n",
       "\u001b[1mSummary:\u001b[0m                                                                                                           \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mLLM:\u001b[0m Text-in, text-out, no memory, no actions.                                                                  \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mAgent:\u001b[0m Goal-in, actions-out, with memory, planning, and tool use.                                               \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "             \u001b[1m3. \u001b[0m\u001b[1mAre agents just two or more LLMs solving problems together and evaluating each other?\u001b[0m              \n",
       "\n",
       "\u001b[1mNot exactly.\u001b[0m                                                                                                       \n",
       "While some agent architectures use multiple LLMs (e.g., one to generate solutions, another to critique), \u001b[1mthe core \u001b[0m \n",
       "\u001b[1midea of an agent is broader\u001b[0m:                                                                                       \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mAgents can use a single LLM\u001b[0m (with code to manage memory, planning, and tool use).                               \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mAgents can use multiple LLMs\u001b[0m (for self-critique, debate, or specialized tasks).                                 \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mAgents can use non-LLM tools\u001b[0m (APIs, databases, calculators, etc.).                                              \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mAgents are defined by their autonomy and ability to act\u001b[0m, not just by having multiple LLMs.                      \n",
       "\n",
       "\u001b[1mSo:\u001b[0m                                                                                                                \n",
       "\n",
       "\u001b[1;33m • \u001b[0mIt’s \u001b[1minaccurate\u001b[0m to say agents are \u001b[3mjust\u001b[0m two or more LLMs solving and evaluating together.                        \n",
       "\u001b[1;33m • \u001b[0mThat’s \u001b[3mone possible architecture\u001b[0m, but not the definition of an agent.                                           \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                   \u001b[1mSummary Table\u001b[0m                                                   \n",
       "\n",
       "                                                               \n",
       " \u001b[1m \u001b[0m\u001b[1mFeature\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStandard LLM\u001b[0m\u001b[1m   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mAgent (LLM-based)\u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       "  Memory          No (stateless)    Yes (stateful)             \n",
       "  Planning        No                Yes                        \n",
       "  Tool Use        No                Yes                        \n",
       "  Autonomy        No                Yes                        \n",
       "  Multiple LLMs   Not required      Optional                   \n",
       "  Example         ChatGPT, Claude   Auto-GPT, LangChain Agent  \n",
       "                                                               \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\u001b[1mIn short:\u001b[0m                                                                                                          \n",
       "\n",
       "\u001b[1;33m • \u001b[0mAn agent is an autonomous system that can plan, act, and use tools (often powered by LLMs).                     \n",
       "\u001b[1;33m • \u001b[0mIt’s not just multiple LLMs working together, though that can be part of an agent’s design.                     \n",
       "\n",
       "Let me know if you want examples or more technical details!                                                        \n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24d8ef",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "[Tools](https://python.langchain.com/docs/concepts/tools/) are utilities that can be called by a chat model. In LangChain, creating tools can be done using the `@tool` decorator, which transforms Python functions into callable tools. It will automatically infer the tool's name, description, and expected arguments from the function definition. You can also use [Model Context Protocol (MCP) servers](https://github.com/langchain-ai/langchain-mcp-adapters) as LangChain-compatible tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afdff275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool # using the tool decorator allows us to create tools easily\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c52ec55b-0b60-4b0c-95d4-ff528a64694e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.tools.structured.StructuredTool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(write_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a40647-3d48-4760-aabe-144d627de110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': {'title': 'To', 'type': 'string'},\n",
       " 'subject': {'title': 'Subject', 'type': 'string'},\n",
       " 'content': {'title': 'Content', 'type': 'string'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_email.args # the tool attributes like arguements and description are automatically infered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd85ae4-9d4c-4efa-9577-aca96e9f22cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Write and send an email.                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Write and send an email.                                                                                           \n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(write_email.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6b427",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "Tools can be [called](https://python.langchain.com/docs/concepts/tool_calling/) by LLMs. When a tool is bound to the model, the model can choose to call the tool by returning a structured output with tool arguments. We use the `bind_tools` method to augment an LLM with tools.\n",
    "\n",
    "![tool-img](img/tool_call_detail.png)\n",
    "\n",
    "Providers often have [parameters such as `tool_choice`](https://python.langchain.com/docs/how_to/tool_choice/) to enforce calling specific tools. `any` will select at least one of the tools.\n",
    "\n",
    "In addition, we can [set `parallel_tool_calls=False`](https://python.langchain.com/docs/how_to/tool_calling_parallel/) to ensure the model will only call one tool at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa57bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect tools to a chat model\n",
    "model_with_tools = llm.bind_tools([write_email], tool_choice=\"any\", parallel_tool_calls=False)\n",
    "\n",
    "#bind tools method allows us to pass a list of tools and some parameters\n",
    "\n",
    "# The model will now be able to call tools\n",
    "output = model_with_tools.invoke(\"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\") # is this is point the llm chooses it's tool and decides it needs to use `write_email` tool. The object it returns is the instructions for calling the tool but doesn't actually call it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7985eab6-9e6b-4fa5-8027-52d32886b97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea0ce030-e760-4679-838f-d88d1480664e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_u6Dgkm6kmO6ebMSuDSPYC6SD', 'function': {'arguments': '{\"to\":\"boss@company.ai\",\"subject\":\"Re: Tomorrow\\'s Meeting\",\"content\":\"Dear [Boss\\'s Name],\\\\n\\\\nThank you for the reminder about tomorrow\\'s meeting. I confirm my attendance and look forward to discussing the agenda items. Please let me know if there is anything specific you would like me to prepare or bring to the meeting.\\\\n\\\\nBest regards,\\\\n[Your Name]\"}', 'name': 'write_email'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 67, 'total_tokens': 158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BnNTrbS5Mk3pP4c5xbpQYzI0rhxIx', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0649203d-5dc7-47f7-9f2e-09baa576ee13-0', tool_calls=[{'name': 'write_email', 'args': {'to': 'boss@company.ai', 'subject': \"Re: Tomorrow's Meeting\", 'content': \"Dear [Boss's Name],\\n\\nThank you for the reminder about tomorrow's meeting. I confirm my attendance and look forward to discussing the agenda items. Please let me know if there is anything specific you would like me to prepare or bring to the meeting.\\n\\nBest regards,\\n[Your Name]\"}, 'id': 'call_u6Dgkm6kmO6ebMSuDSPYC6SD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 67, 'output_tokens': 91, 'total_tokens': 158, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1a240ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AI Message Output ===\n",
      "Content: \n",
      "Additional kwargs:\n",
      "{'refusal': None,\n",
      " 'tool_calls': [{'function': {'arguments': '{\"to\":\"boss@company.ai\",\"subject\":\"Re: Tomorrow\\'s '\n",
      "                                           'Meeting\",\"content\":\"Dear [Boss\\'s Name],\\\\n\\\\nThank '\n",
      "                                           \"you for the reminder about tomorrow's meeting. I \"\n",
      "                                           'confirm my attendance and look forward to discussing '\n",
      "                                           'the agenda items. Please let me know if there is '\n",
      "                                           'anything specific you would like me to prepare or '\n",
      "                                           'bring to the meeting.\\\\n\\\\nBest regards,\\\\n[Your '\n",
      "                                           'Name]\"}',\n",
      "                              'name': 'write_email'},\n",
      "                 'id': 'call_u6Dgkm6kmO6ebMSuDSPYC6SD',\n",
      "                 'type': 'function'}]}\n",
      "\n",
      "Tool calls:\n",
      "  1. Function: Unknown\n",
      "     Arguments: {}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "\n",
    "print(\"=== AI Message Output ===\")\n",
    "print(f\"Content: {output.content}\")\n",
    "print(f\"Additional kwargs:\")\n",
    "pprint.pprint(output.additional_kwargs, width=100)\n",
    "\n",
    "# If you want to see tool calls specifically\n",
    "if output.tool_calls:\n",
    "    print(\"\\nTool calls:\")\n",
    "    for i, tool_call in enumerate(output.tool_calls, 1):\n",
    "        print(f\"  {i}. Function: {tool_call.get('function', {}).get('name', 'Unknown')}\")\n",
    "        print(f\"     Arguments: {tool_call.get('function', {}).get('arguments', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b1a9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'write_email',\n",
       " 'args': {'to': 'boss@company.ai',\n",
       "  'subject': \"Re: Tomorrow's Meeting\",\n",
       "  'content': \"Dear [Boss's Name],\\n\\nThank you for the reminder about tomorrow's meeting. I confirm my attendance and look forward to discussing the agenda items. Please let me know if there is anything specific you would like me to prepare or bring to the meeting.\\n\\nBest regards,\\n[Your Name]\"},\n",
       " 'id': 'call_u6Dgkm6kmO6ebMSuDSPYC6SD',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tool_calls[0] # list of tools the llm wants to call. in this case it's write_email tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "717779cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 'boss@company.ai',\n",
       " 'subject': \"Re: Tomorrow's Meeting\",\n",
       " 'content': \"Dear [Boss's Name],\\n\\nThank you for the reminder about tomorrow's meeting. I confirm my attendance and look forward to discussing the agenda items. Please let me know if there is anything specific you would like me to prepare or bring to the meeting.\\n\\nBest regards,\\n[Your Name]\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract tool calls and execute them\n",
    "args = output.tool_calls[0]['args'] # extracts the arguments the LLM wants to use. \n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09f85694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Email sent to boss@company.ai with subject 'Re: Tomorrow's Meeting' and content: Dear [Boss's Name],               \n",
       "\n",
       "Thank you for the reminder about tomorrow's meeting. I confirm my attendance and look forward to discussing the    \n",
       "agenda items. Please let me know if there is anything specific you would like me to prepare or bring to the        \n",
       "meeting.                                                                                                           \n",
       "\n",
       "Best regards, [Your Name]                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Email sent to boss@company.ai with subject 'Re: Tomorrow's Meeting' and content: Dear [Boss's Name],               \n",
       "\n",
       "Thank you for the reminder about tomorrow's meeting. I confirm my attendance and look forward to discussing the    \n",
       "agenda items. Please let me know if there is anything specific you would like me to prepare or bring to the        \n",
       "meeting.                                                                                                           \n",
       "\n",
       "Best regards, [Your Name]                                                                                          \n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the tool\n",
    "result = write_email.invoke(args)\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ed7f0",
   "metadata": {},
   "source": [
    "while not done:  \n",
    "    1. LLM decides what to do  \n",
    "    2. Execute tools (if any)  \n",
    "    3. Add results to conversation  \n",
    "    4. Repeat until final answer  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9c52a",
   "metadata": {},
   "source": [
    "![basic_prompt](img/tool_call.png)\n",
    "\n",
    "## Workflows\n",
    " \n",
    "There are many patterns for building applications with LLMs. \n",
    "\n",
    "[We can embed LLM calls into pre-defined workflows](https://langchain-ai.github.io/langgraph/tutorials/workflows/), giving the system more agency to make decisions. \n",
    "\n",
    "As an example, we could add a router step to determine whether to write an email or not.\n",
    "\n",
    "![workflow_example](img/workflow_example.png)\n",
    "\n",
    "## Agents\n",
    "\n",
    "We can further increase agency, allowing the LLM to dynamically direct its own tool usage. \n",
    "\n",
    "[Agents](https://langchain-ai.github.io/langgraph/tutorials/workflows/) are typically implemented as tool calling in a loop, where the output of each tool call is used to inform the next action.\n",
    "\n",
    "![agent_example](img/agent_example.png)\n",
    "\n",
    "Agents are well suited to open-ended problems where it's difficult to predict the *exact* steps needed in advance.\n",
    " \n",
    "Workflows are often appropriate when the control flow can easily be defined in advance. \n",
    "\n",
    "![workflow_v_agent](img/workflow_v_agent.png)\n",
    "\n",
    "## What is LangGraph? \n",
    "\n",
    "[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) provides low-level supporting infrastructure that sits underneath *any* workflow or agent. \n",
    "\n",
    "It does not abstract prompts or architecture, and provides a few benefits:\n",
    "\n",
    "- **Control**: Make it easy to define and / or combine agents and workflows.\n",
    "- **Persistence**: Provide a way to persist the state of a graph, which enables both memory and human-in-the-loop.\n",
    "- **Testing, Debugging, and Deployment**: Provide an easy onramp for testing, debugging, and deploying applications.\n",
    "\n",
    "### Control\n",
    "\n",
    "LangGraph lets you define your application as a graph with:\n",
    "\n",
    "1. *State*: What information do we need to track over the course of the application?\n",
    "2. *Nodes*: How do we want to update this information over the course of the application?\n",
    "3. *Edges*: How do we want to connect these nodes together?\n",
    "\n",
    "We can use the [`StateGraph` class](https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs) to initialize a LangGraph graph with a [`State` object](https://langchain-ai.github.io/langgraph/concepts/low_level/#state).\n",
    "\n",
    "`State` defines the schema for information we want to track over the course of the application. \n",
    "\n",
    "This can be any object with `getattr()` in python, such as a dictionary, dataclass, or Pydantic object: \n",
    "\n",
    "- TypeDict is fastest but doesn’t support defaults\n",
    "- Dataclass is basically as fast, supports dot syntax `state.foo`, and has defaults. \n",
    "- Pydantic is slower (especially with custom validators) but gives type validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84bedb9",
   "metadata": {},
   "source": [
    "Each node is simply a python function or typescript code. This gives us full control over the logic inside each node.\n",
    "\n",
    "They receive the current state, and return a dictionary to update the state.\n",
    "\n",
    "By default, [state keys are overwritten](https://langchain-ai.github.io/langgraph/how-tos/state-reducers/). \n",
    "\n",
    "However, you can [define custom update logic](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers). \n",
    "\n",
    "![nodes_edges](img/nodes_edges.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da35cb4",
   "metadata": {},
   "source": [
    "Core Concepts You'll Learn:\n",
    "\n",
    "State - What information to track (like conversation history, user preferences)  \n",
    "Nodes - Functions that update the state (LLM calls, tool executions)  \n",
    "Edges - How nodes connect (conditional logic, loops)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3319290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class StateSchema(TypedDict): #building a workflow that tracks request and email data\n",
    "    request: str\n",
    "    email: str\n",
    "\n",
    "workflow = StateGraph(StateSchema) # initialise the state graph with our custom scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a39c043b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.channels.last_value.LastValue at 0x17d3e612500>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.schemas[StateSchema][\"request\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5e79c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool # using the tool decorator allows us to create tools easily\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\"\n",
    "\n",
    "\n",
    "\n",
    "def write_email_node(state: StateSchema) -> StateSchema: #creation of node \n",
    "    # Imperative code that processes the request\n",
    "    output = model_with_tools.invoke(state[\"request\"])\n",
    "    args = output.tool_calls[0]['args']\n",
    "    email = write_email.invoke(args)\n",
    "    return {\"email\": email} # this function returns a dictionary with updates state data\n",
    "\n",
    "# state is the current data in the graph. It's a dictionary with `request` and email keys. As defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acfe30",
   "metadata": {},
   "source": [
    "This function:\n",
    "\n",
    "Takes current state as input  \n",
    "Processes it (calls LLM + tools)  \n",
    "Returns updated state  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c8040",
   "metadata": {},
   "source": [
    "Edges connect nodes together. \n",
    "\n",
    "We specify the control flow by adding edges and nodes to our state graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "554e0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(StateSchema)\n",
    "workflow.add_node(\"write_email_node\", write_email_node) # converts/registers the function into/as a node.  workflow.add_node(node_name,function_name)\n",
    "workflow.add_edge(START, \"write_email_node\") # START flows to this node\n",
    "workflow.add_edge(\"write_email_node\", END) #This node flows to end\n",
    "\n",
    "#Execution engine: runs the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72157836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKsAAADqCAIAAABSjiKHAAAAAXNSR0IArs4c6QAAGfRJREFUeJztnXd8FGXCx5/tfdM2PYFkSYFA+pIAAkcJNXQ4FGlBiqEISPGQUxABFUEFOdpB0KOcBJQmVUJAhJPwJoFUIaSSTjbZbG8zu+8fy2dF2BTDbp6Jz3z/2p3yPL/sfPPMMzPPzFDMZjMgQRgq7AAkkCENQB3SANQhDUAd0gDUIQ1AHTrsAG1TW6ZTyzG1AsMxoNfisOO0DYtLo9MpXCGNJ2R4B7Jgx2kDCmHPBxRmKMoK1GX56h4RfAoFcIU0Fw+mQWuCnattmByqrN6gVuAUCijOVYl788Th/J59BbBz2YaIBuTcav7fhcaQGEFgH564Nw9QYAd6BcxmUJavLi9UF2UrB4wXRQx0gp3oRYhlwNNK/dUjdd3DuK+NE9EYXXnLvwRmMN+5IK0q0o6c7enuS6BdA4EM+O2eIu+OfNwCH66ABjuLo1DL8R8P1UQNdibOToEoBpTla0ryVAkzPGAH6QzS/lsfHCXoHsaFHQQQxYCs67KmOsOImZ6wg3QeV4/We/ixooc6ww5CgPMB5YWamlItUpsfADBqtmdlkebJQw3sILANUDVjBXfl4xf6wI0BhQlv++TdkavlkM9wQDbg9jlpaAxR+kSdT3A0//b5BrgZYBrwtFIvbzQGRfEhZoBLSIxAVm+Q1hggZoBpQMFdxcAJIogBiMDAie75/5NDDADNAMxofpip8A3idGalqampGzdu7MCKCQkJ1dXVDkgE/II5hXflJnidAWgGlBWoA3vzOrnSgoKCDqxVVVXV3NzsgDjPCOjNKytQO6781oF2PuCXs1LfHhxxuEMkKC0tPXDgQGZmJo1Gi4iImD17dmRk5Pz583NyciwLnDhxIigoKDU19ZdffsnPz2exWBKJZOnSpT4+PgCANWvWMJlMT0/Po0ePLlq06N///rdlrWHDhn3++ed2T1uco64r1w6cCGeHCK0NqCvX8oQOOftrMBiSk5OZTOaBAwd2794NAFi1apVer09JSenTp09iYmJmZmZQUFBWVtb27dujo6N37NixadOm+vr6Dz/80FICg8EoLCwsKSn56quvpk+fvnPnTgDAuXPnHLH5AQA8Ia2+QueIktsDtPEBagXOFTqk9oqKiqamphkzZgQFBQEAtm3bdv/+fQzDWKw/XI+JiopKTU0NCAig0WgAAJ1Ot2bNGpVKxefzaTRaQ0NDamrqC6s4CJ6QplZgnVCRTaAZoFFgPMcY0K1bNxcXlw0bNiQmJsbGxkZEREgkkpcXo9FolZWVO3bsKCwsVKuf7Yabmpr4fD4AIDAwsHM2PwCAK6SrldC6gtD2AlQ6heKYylks1sGDBwcOHHj8+PG33npr8uTJV65ceXmx9PT0NWvWREZGpqSkZGZmWpr65wtxSDhbUKmARoN2KRyaAWwuTS13VNMXEBCwcuXKCxcu7NixQywWf/DBB0VFRS8sc+bMmejo6OTkZMvOQqVSOShMm6jkOJsL718RVsVcIU2tcEjTV1ZW9uOPPwIA2Gz2kCFDtm3bRqVSHz58+MJicrnc3d3d+jU9Pd0RYdqDWoE5qEvUHqAZ4B3A0Sod0gbIZLJNmzbt3LmzqqqqtLT08OHDJpMpIiICAODv719YWJiZmSmTyUJCQu7du5ednY1h2LFjxyz9wbq6upcLDAgIAACkpaV17HRCm2hVuFd3tiNKbg/QDPDwZxXdd0jDGxMTs379+suXL0+aNGn69Om5ubkHDhywbMUpU6aYzeYlS5aUlJQsW7YsLi5u5cqV/fv3l0qlH330UWho6JIlS15uDPz8/MaPH79v3749e/Y4IvDjbKVnN2gGADMkDDp8/7piWLUTir3vFRsNJli1Q2sDGCxqcJSgrgzamRCCUFOi6xkrpMMbFgvzjpGweOHtc9JpK/xaWuCdd97Jy8t7eTqGYQAAOt12+AsXLliO6e1Obm7u8uXLbc7CMKylPACAGzduUCi2t/Ht8w1DpsIcHQl5nODFw7W94oTiPravDkilUoPB9rVzvV7f0iG75dy+g6ipqenAWi1FKslVFWUrxyR5v3KujgPZgOYG7O4l6ei5XhAzQOTyt3UDxouc3GC2xJBHiTm704Oi+Je/tXEM9pfn0uHa0FgB3M0P3wAAQFAk39WLeeMk5OFynUz6iafufiwHXRz/UxDifgEAQFG2qrZM+7ep7u1Ytstz89RTv2AuQQZIwm8DLITE8F08mGf2VBv1XeDu4A5j0Jl++FeVmw+LIJufQG2Ahepi7U9H63rGC/uPdYOdxf78erHxUZZy5CwvHzG8M4AvQSwDLGSmyTIuN4YPdBL34fsFd+pQUkdQWaQtL1Tn3Grun+gWO8yFaDfDE9EAAIDZBHJvN5cVqOvKdUGRfAqVwhXSnEVMo6ELPEOEwaQ2NxjVCgyYweMclXcAWxzOj3jNiWjb3gJBDbCCGcy1ZTqV3KhW4GaTWaOypwFms/n8+fMTJ060Y5kAAA6PRqNRuEIa34nhLWZDPOPbHohugEPBcXzAgAEZGRmwg8CEKMcCJLAgDUAd0gDUIQ1AHdIA1CENQB3SANQhDUAd0gDUIQ1AHdIA1CENQB3SANQhDUAd0gDUIQ1AHdIA1CENQB3SANQhDUAd0gDUIQ1AHdIA1EHaAAqFYnmIHMogbYDZbMbxLnAbmkNB2gAS0gAS0gDkIQ1AHdIA1CENQB3SANQhDUAd0gDUIQ1AHdIA1CENQB3SANQhDUAd0gDUQfSJkpGRkS+8FshkMt2/fx9eImgg2gb4+flR/ohD305EZBA1QCKRPN/4mUymmJgYqImggagBM2fO9PL6/fVWPj4+SUlJUBNBA1EDQkJCJBKJ9WtMTEyPHj2gJoIGogZYmgFPT08AgIeHx9y5c2HHgQa6Blibgfj4eGQbgHYdDVYX66Q1eo1j3hQPF5lMdu3atYSEBFdXV9hZ7A9XQBN5s32D23inUWsG6LWmM3urWRyasweLxUa3teii6LW4XGrQa/HJS3yZLW++Fg3Qa00/HqyVjBC5+dh+vS9Jl0Barc++Lh2/0LslCVpU4+y+anLz/wUQ+bKih7md3d/iC7NtG1BdomMwqeTm/2vg7sem0Si1ZTqbc20bIK3WuXoR6K2IJK+IiyerofrPGKBR4q30HUi6HEwOVaO0/TpfcjOjDmkA6pAGoA5pAOqQBqAOaQDqkAagDmkA6pAGoA5pAOqQBqAOaQDqQDOg6PHDocMlBQW5sAK0n1PfHx85ur/l86QpCUeOHuqEStOuXxk6XKJQKhxdETQD3FxFc2YvEIk8AAClpcVvvDkOVpI2CesVPmvmfNgpHAW9Hcs4BDc30bykZMvn3x7mw4rRHnr3jujdOwJ2CkdhnzZgyrSRx44ftnyWShuGDpds3rLeOnfCpGEnTx37/of/Tps++vadmwkj4/fu+8q6FziUsmfHF1vq6+uGDpf8cPqEpYSPN7//+ozESVMSPvlsQ3VNVXsy5OU9WLN2yfgJQ+bOm7Zv/06tVmuZ/sMP3039+6iixw9fn5E4YlS/+QvfKPwt//adm+MnDhk7btCmj9fJFXLLkr/++svWTz6Y/sbYseMGrV6z+MGDLMv05/cC7cFSY0VF2dx504YOl8xf+MbVqxesc588KV+1Ojlx/OCJk4eveHdhTk62ddb+A7umTBs5a/akb77db/rjI68vXT63eOncMYkDl74zz/Ir2Qv7GBAf91rhb3mWzw9ysjw9vfILcixfnzwpVyoVkth+DAZTq9WcSD2y/v3NEyZMs667YP7SN16f4+npdeN65tQpb2AYtmpNcl7+gzWrP/wm5aRAIFy8eHZtXYvD3Ky1vLdumREz7t3zn40ffvb48cNVa5JNJhMAgMFkKpWKI0cPfrFj/7kz6Tqd7tPPNvz008XDh04e+fZ0Vva906e/AwBoNJotn/wTw7D31328dctXvr7+//zw3eZmWQd+DUuNu77etu69j9LT/m/ga0O2f7FZKm0AAMhkTcvemefj43fo4Indu1KchM6bt67X6/UAgHPnvz93/tSK5f/Yu/eIp6f3kWO/9zauXbu0fcfmnqFh3x3/cV5S8slTR/fu+6oDwWxiHwOioyT5+c82eX7+g+HDRjc1NdbX1wEAcvPuu7mJxOIgGo2m0Wjmv7Vk2NCRfr7+LRWVk5tdWVnx/rqP+0r6ubi4Ll28is8X/PDDd60HSLt+mUFnfPzRdn//7mJx0OrVHzx8WPC/X28BAKhUqtFoTJrztp+vP5fLjY9/rba2etW7693dPUQi9/DwqJLSxwAALpd76OCJlSvWRUdJoqMkixYu12g01j/qT2GpcV5Scq9efSgUysiR43AcLy5+ZGlO2BzOyhXrvL18unULWLt2g0Ihv3jxDADg9JkTfxuc8LfBw4UC4dgxE6MiY60F/njxdERE9Irl/3B2dpHExs+ds+j0mRNqtboD2WyktUspsbHxSqWioqLMsgnD+0T17Nk7L/+BxYCYmDjrkqEhYa0XlZf3gMFgxET3fZaPSo2IjMnLa+PO/vz8nJ49ezs5OVu++vr4eXl6P9/A9ugRbPnA5XDd3ETOzi7WryqV0vJZo1Z/vfvzadNHDx0uGT9xCACgWd6RNsBCz569LR8EAiEAQKVWAQBKy4pDQ8Ksjy4Q8AX+/t0fFhWazebq6sqAALF19dDQZz8UhmGFhXl9Jb/vhqKj++I4XlX9pMPZnsc+PUE3N1G3bgF5+Q+cnV0qKsoiImJycrPz8u4nDB+dm5udNPdt65JMJrP1olQqpdFoHDpc8vxENzdRm2s9Ln70wloyWaP1M4VCsfnZSl1d7Yp3F/SV9N/wwadhYeE4jo8e+1rrlbaOzVqaGqXdugU8P4XN5mg1GrVajeM4j8f/fTrr2UhdnU6H43jK4b0ph/c+v6JarXqVeFbsdiwQGxufn58jEAiDeoRwudyI8OhDh/dIpQ319XVxfQe0vxw3NxGHw9m65Q/7OTqtjZyubqJwDsd6cGHBSejc/nrTb1w1Go3/eO8jNpsNAJDLm9u/bvvh8ng6/R/G7Gq1GregUB6PR6PRDHq9dbpGq7F84PP5bDZ79KjxgwcPf35FsTjYLpHsZkBMdN+9e7/k8wXhEdEAgD7hUaWlxTd/viYWB7m6urW/HLE4WKvVenn5eHs9e6hHdU2Vq0sbJfQQB9+48VNUZKz1P6+8vNTPr1v765XLmwUCoWXzAwBu/pzW/nXbT2hI2LW0SxiGWXYEcnlzZWXFxAl/p1Aonp7eBYW5U6fOsCx5N+O2dS2xOFir00ZHPWvhDAZDfX2tk9DJLpHsdkYoKlJS/7Tu7t1fwvtEWfZwYnHQmTOpMdFxba7r59etsVF6587PVVVP4uMGxMUN2L794/r6uuZm2ekzqcnJs67+dKH1EqZPn43h2L/2fqHT6Z48Kd9/YNdbC1639EvaSVCPkMZG6cVLZzEMu5txJz//AZ/Hf/q0rv0ltIdxiZOVSsWXX31SX19XWlr86baNXC5v1MhxAIChQ0bcuHnt51vXAQDH//vNo0eF1rXeXrj81q3rly6fw3E8N/f+ps3rVq9djGH2uZfXbgbw+fyQkF7VNVVWVfv0jqyprbb26VqhX/zA8D5RH2xYnX7jJwDAp1t3Dh48/OMt70+eOuLc+VNjxkycNPHvrZfgJHRKOZTKZrEXLJoxd960nNzsf6zdaO39tYeEhDEz35z3zbf7R4zqd+Zs6jvL1o4YmXj0WMruPTvaX0ib+Pt337jhs5KSojfeHLd67WIqlbp7V4ql4Zk1c/7oUeN3fb1t6HBJZubd5EUrLO/CAgBEREQf2HcsN/f+5CkJ761bptVotmz+8oUnYXUY23eO/nqx0Wymhg9ysUsdJNDJudVEp4N+Y2zcJE9eG0QdaNcF/iypJ48eO5Zic1agOOjrnZ1xvY6YYV6RLrMXUKqU1lM3L8CgM0Qid2TDtIdW9gJdpg0Q8AUCvgB2imcQKswrQvYDUIc0AHVIA1CHNAB1SANQhzQAdUgDUIc0AHVIA1DHtgFcAc2gs/3wMZKuiEFn4gppNmfZNkDky5bV623OIumKyOr17i08Ida2Ab492EYDLq0mJfgr8LRSZ8LN3oG2HxLbYj9gYrJvdpq0sYaUoGsjrdbfT2+c+HaLb1Jr4/0CZ/dVszg0Z3cWk0P2GbsYejWuaDLotfikxR16v4CVqmJdY41eo/gLvmPEbDYfP3581qxZsIM4BI6AJvJh+QVzWl8M0XeOWsBxfMCAARkZGbCDwIRs21GHNAB1SANQhzQAdUgDUIc0AHVIA1CHNAB1SANQhzQAdUgDUIc0AHVIA1CHNAB1SANQhzQAdUgDUIc0AHVIA1CHNAB1SANQhzQAdZA2gEKhMBgM2Ckgg7QBZrPZaDTCTgEZpA0gIQ0gIQ1AHtIA1CENQB3SANQhDUAd0gDUIQ1AHdIA1CENQB3SANQhDUAd0gDUIQ1AHdIA1EH0iZJRUVF0Ot1kMlEoz34BCoWSlZUFOxcEEG0DfH19AQBUKpVCoVCpVCqV6unpCTsUHBA1oG/fvs9/NZlM/fr1gxcHJogaMGfOHHf3398P7e3tPXv2bKiJoIGoAWKxOD4+3vo1Li4uMDAQaiJoIGqApRmw7Ps9PDySkpJgx4EGugaIxeK4uDgAQL9+/bp37w47DjS6zNFg1WOtqhlTyzEMM2tVuF3KVKlUt27dGjRokEAgsEuBHB6VzqTyhHS+M73NVzsQBKIbUJStfJStqihUewUJMYOJxqDTWXSTiaCZKVQKrjfiRpzBoNaWKrr34oVGC0Ji+bBztQZxDfjtnuL2+UYXbz6Tzxa6cwEFdqA/ixkoGtQGtb65VjVwgqhnX/s0M3aHiAao5fil/9TjJqoo0JXOtP2exC4EpscbypoYdFPiPE8On3B/DuEMePJQc+VofUCsL5NDuB/rVTBo8fLMqjFJXv4hXNhZ/gCxDHhapb96XOof4QU7iKOozKkdPdvd3df26z+hQCADSnJVv15u9ovwhh3EsVQ+qB043iWwDw92kGcQ5XyAXGr8+bT0L7/5AQD+Ud7pJxsUTUR5fyNRDLh6tCGwrz/sFJ1EYJz/1WP1sFM8gxAG/HqxCTCZFEJk6QyoNGCmsu5dbYIdBBDCABwzZ99o8hC7wA7SqXj0cLn3U5PZBDsHEQzIui7z7SWCnaJFTp379Is9DnkxsX+YKPO6zBEl/yngG1CYoeQ6s2GngADbiV2YoYCdArYBsqdGkwkwuSg+0IvFY2BGs1wK+VFWdLjVVxZpnLwceMI8I+t8RubZuvoSb6/gqPARg/q/bpn+4daEMSMWK5WN126msFm80OD+E8euEgrcAAB6veb49xuKSzO9PYNei5/muGwAABdfQWWRxknk5NBaWgdyG9BQbQBUR13zyXpw+dTZrX4+vdavPjtq2KKf7xw/f3mXZRaDwUq/dYTBYG1en7Z2eWpp+f1rN1Mss06e3SptrFz81t65M7ZV1xYVFd91UDwAgNlMldYYHFd+e4BsgFqOMViOaofuZp4Vd4+eMn4tn+cSEhQ3YuiC23dT1epmAAAAFA9Rt2GD53I4Aiehe0iPuOqaRwAAuaIhJz9t6MDZ/r5hQoHbuFHv0GlMB8UDANBZNFWzfcY6dBjIBmhVOIPlkCtAOI5VVOaFBP8+GDBYLDGZ8LKKHMtXP99e1lkcjlCrUwIAmmTVAABPj2djBikUip9PT0fEs8Bg0e012qXDQO4HmM3AQdclDEadyYRfSdt/JW3/89OVaut5GBt7H7VGDgBgs34f08FkOnCoj9lshn5dBrIBPCENM2AA2P9aGYfNZzLYkuhxEb2HPT9d5ObXWh6uEwDAiOmtU3R6td2zWcH0OM8J8iaAXD3fid7ksB2ht1ewwagNEsdavhoxg0xW6+zU2r1BLs4+AICKyjxf7xAAgMGgKy7NFArdW1nlVcAMuLM75E0AuR/g7seiOOzUaOLIpbkF6RlZ53EcLy2/fzR1/YFvlxmx1vrezk4eAd0ir6TtlzZWGo3646c+pFAd+ROZTe4+DuxptgfIBnQL5ciqlQ4qXBwQvTL5P2XlDz76bNTBIyv0es28mdsZ9DZ+8RlTN/r59vpyz6x/bhkq4LtJohId1VUBQFat9A+FPGQI/giRI1srPEM8WXzkTgvqlAZpScOs97vBjQH/ukBYvFAt08JOAQFNsy6sH/wBxJC7IQAASYLL3VXFrv7Clha4m3n2wtXdNmfhuJFGs914vDl1U1jPgfYKefP2sbSfv7E5i8MWanW2L/AsnLOru38fm7PMZlD7qHHKoiB7Jeww8PcCAIDMNFnpQ8yjh6vNuVqdSqu1/RNrtEoux/a/EZ/nymTa7ZKjVqu0nDJ6GaNRz2DYPpoVCEQtdTvqHzeGRDCjhzjbK2GHgd8GWJqBJ49qcANOs3V3AIfN57Bt33bj2lnDSjgcAacF1TqAUY8z6Vj0EA97FfgqwO8HWBgz17Mkowp2ik6i5G7V2CSijIgnigEcPm1MkldFVg3sIA6nPKtm3AIvFpcovzwh+gFWZE+N5w/WdY/xgR3EUZRnVk9K9nZ2J9ChL1FMtODiwRg926MwvVynhHzV3O5oFYaC62VjkzwJtfkJ1wZYwIzmS9/WqeRmtwBXFo9Yv1cH0KuN0rImoTMl8S0vKo1wt0AT0QALpXnqX85K2UI2k8cSevBoDGI1V22CG02Kp2qDWq9T6gZNEokJc5vYCxDXAAvlBepH2eryQpWLN8+gw2lMGp3FMJsIMM7eFlQqDdMbMAPOZNNkterA3vyQGF5AGEG3vQWiG2DlaaVeLcc0StygN+m1BDWAxaEwWTSugMZzonv4E+gG4VboMgaQOIgutnMlsTukAahDGoA6pAGoQxqAOqQBqEMagDr/DxkkcXcn6lcOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cc79b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request': \"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\",\n",
       " 'email': \"Email sent to boss@company.ai with subject 'Re: Tomorrow's Meeting' and content: Dear [Boss's Name],\\n\\nThank you for the reminder about tomorrow's meeting. I confirm my attendance and will be prepared with the necessary updates and materials.\\n\\nPlease let me know if there are any specific topics you would like me to address or if there are any changes to the agenda.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n[Your Name]\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"request\": \"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\"}) # pass an inital value to our state here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446dea9",
   "metadata": {},
   "source": [
    "Routing between nodes can be done [conditionally](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges) using a simple function. \n",
    "\n",
    "The return value of this function is used as the name of the node (or list of nodes) to send the state to next. \n",
    "\n",
    "You can optionally provide a dictionary that maps the `should_continue` output to the name of the next node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f29b05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import MessagesState\n",
    "from email_assistant.utils import show_graph\n",
    "\n",
    "def call_llm(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"Run LLM\"\"\"\n",
    "\n",
    "    output = model_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [output]} # append to the list of messages instead of overwriting\n",
    "\n",
    "def run_tool(state: MessagesState):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        observation = write_email.invoke(tool_call[\"args\"])\n",
    "        result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "    return {\"messages\": result}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"run_tool\", \"__end__\"]:#\n",
    "    \"\"\" This is a conditional edge with returns the name of the next node you want to go to\"\"\"\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    \n",
    "    # Get the last message\n",
    "    messages = state[\"messages\"] #list of messages\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the last message is a tool call, check if it's a Done tool call\n",
    "    if last_message.tool_calls: #check if last message is a tool call \n",
    "        return \"run_tool\" #return the name of the next node to go to 'run_tool'\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "workflow = StateGraph(MessagesState) #MessageState is a pre-built state object in LangGraph with a single key, messages\n",
    "workflow.add_node(\"call_llm\", call_llm)\n",
    "workflow.add_node(\"run_tool\", run_tool)\n",
    "workflow.add_edge(START, \"call_llm\")\n",
    "workflow.add_conditional_edges(\"call_llm\", should_continue, {\"run_tool\": \"run_tool\", END: END}) #if the agent is making a tool call we run it, if not we exit the agent and end the loop\n",
    "workflow.add_edge(\"run_tool\", END)\n",
    "\n",
    "# Run the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd9f07af-c633-4527-b2d9-52c6451dc9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dadbafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  write_email (call_uO5uKVaeSDgdPaOPqKzogOUD)\n",
      " Call ID: call_uO5uKVaeSDgdPaOPqKzogOUD\n",
      "  Args:\n",
      "    to: boss@company.ai\n",
      "    subject: Confirmation: Attendance at Interrupt!\n",
      "    content: Hi,\n",
      "\n",
      "Thank you for letting me know about Interrupt! I would like to confirm that I am interested in attending the event.\n",
      "\n",
      "Please let me know if there are any next steps or additional details I should be aware of.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Email sent to boss@company.ai with subject 'Confirmation: Attendance at Interrupt!' and content: Hi,\n",
      "\n",
      "Thank you for letting me know about Interrupt! I would like to confirm that I am interested in attending the event.\n",
      "\n",
      "Please let me know if there are any next steps or additional details I should be aware of.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\"}]})\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b232d",
   "metadata": {},
   "source": [
    "With these low level components, you can build many many different workflows and agents. See [this tutorial](https://langchain-ai.github.io/langgraph/tutorials/workflows/)!\n",
    "\n",
    "Because agents are such a common pattern, [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/workflows/#pre-built) has [a pre-built agent](https://langchain-ai.github.io/langgraph/agents/overview/?ref=blog.langchain.dev#what-is-an-agent) abstraction.\n",
    "\n",
    "With LangGraph's [pre-built method](https://langchain-ai.github.io/langgraph/tutorials/workflows/#pre-built), we just pass in the LLM, tools, and prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a317ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  write_email (call_3cwt26mLSZLmLpiQhr5VbYua)\n",
      " Call ID: call_3cwt26mLSZLmLpiQhr5VbYua\n",
      "  Args:\n",
      "    to: boss@company.ai\n",
      "    subject: Confirmation: Attendance at Interrupt!\n",
      "    content: Hi,\n",
      "\n",
      "Thank you for letting me know about Interrupt! I would like to confirm that I am interested in attending the event.\n",
      "\n",
      "Please let me know if there are any next steps or additional details I should be aware of.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_email\n",
      "\n",
      "Email sent to boss@company.ai with subject 'Confirmation: Attendance at Interrupt!' and content: Hi,\n",
      "\n",
      "Thank you for letting me know about Interrupt! I would like to confirm that I am interested in attending the event.\n",
      "\n",
      "Please let me know if there are any next steps or additional details I should be aware of.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've drafted and sent a response to your boss confirming your interest in attending Interrupt! If you need to make any changes or add more details, let me know.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[write_email],\n",
    "    prompt=\"Respond to the user's request using the tools provided.\"  \n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\"}]}\n",
    ")\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e506f",
   "metadata": {},
   "source": [
    "### Persistence\n",
    "\n",
    "#### Threads\n",
    "\n",
    "It can be very useful to allow agents to pause during long running tasks.\n",
    "\n",
    "LangGraph has a built-in persistence layer, implemented through checkpointers, to enable this. \n",
    "\n",
    "When you compile graph with a checkpointer, the checkpointer saves a [checkpoint](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints) of the graph state at every step. \n",
    "\n",
    "Checkpoints are saved to a thread, which can be accessed after graph execution completes.\n",
    "\n",
    "![checkpointer](img/checkpoints.png)\n",
    "\n",
    "We compile the graph with a [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a72377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[write_email],\n",
    "    prompt=\"Respond to the user's request using the tools provided.\",\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What are some good practices for writing emails?\"}]}, config)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10984007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some good practices for writing emails?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some good practices for writing effective emails:\n",
      "\n",
      "1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what to expect.\n",
      "\n",
      "2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\n",
      "\n",
      "3. **Be Concise and Direct:** Get to the point quickly. Use short paragraphs and avoid unnecessary details.\n",
      "\n",
      "4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it is free of errors.\n",
      "\n",
      "5. **Be Polite and Professional:** Use courteous language and maintain a professional tone, even if the email is informal.\n",
      "\n",
      "6. **Structure Your Email:** Use paragraphs, bullet points, or numbered lists to organize information clearly.\n",
      "\n",
      "7. **State Your Purpose Early:** Let the recipient know why you are writing within the first few sentences.\n",
      "\n",
      "8. **Include a Call to Action:** If you need a response or action, state it clearly.\n",
      "\n",
      "9. **Sign Off Properly:** End with a polite closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\n",
      "\n",
      "10. **Use a Professional Signature:** Include your contact information and job title if appropriate.\n",
      "\n",
      "11. **Be Mindful of Tone:** Avoid using all caps (which can seem like shouting) and be careful with humor or sarcasm, as it can be misinterpreted.\n",
      "\n",
      "12. **Reply Promptly:** Respond to emails in a timely manner, ideally within 24 hours.\n",
      "\n",
      "Would you like tips for a specific type of email (e.g., business, networking, follow-up)?\n"
     ]
    }
   ],
   "source": [
    "# Get the latest state snapshot\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "state = agent.get_state(config)\n",
    "for message in state.values['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f23ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some good practices for writing emails?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some good practices for writing effective emails:\n",
      "\n",
      "1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what to expect.\n",
      "\n",
      "2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\n",
      "\n",
      "3. **Be Concise and Direct:** Get to the point quickly. Use short paragraphs and avoid unnecessary details.\n",
      "\n",
      "4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it is free of errors.\n",
      "\n",
      "5. **Be Polite and Professional:** Use courteous language and maintain a professional tone, even if the email is informal.\n",
      "\n",
      "6. **Structure Your Email:** Use paragraphs, bullet points, or numbered lists to organize information clearly.\n",
      "\n",
      "7. **State Your Purpose Early:** Let the recipient know why you are writing within the first few sentences.\n",
      "\n",
      "8. **Include a Call to Action:** If you need a response or action, state it clearly.\n",
      "\n",
      "9. **Sign Off Properly:** End with a polite closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\n",
      "\n",
      "10. **Use a Professional Signature:** Include your contact information and job title if appropriate.\n",
      "\n",
      "11. **Be Mindful of Tone:** Avoid using all caps (which can seem like shouting) and be careful with humor or sarcasm, as it can be misinterpreted.\n",
      "\n",
      "12. **Reply Promptly:** Respond to emails in a timely manner, ideally within 24 hours.\n",
      "\n",
      "Would you like tips for a specific type of email (e.g., business, networking, follow-up)?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! Here’s a concise and direct email response to your boss, confirming your interest in attending Interrupt, following lesson 3:\n",
      "\n",
      "---\n",
      "\n",
      "**Subject:** Confirmation: Attendance at Interrupt\n",
      "\n",
      "Hello [Boss’s Name],\n",
      "\n",
      "Thank you for the opportunity. I would like to confirm that I am interested in attending Interrupt.\n",
      "\n",
      "Please let me know if there are any next steps or additional information you need from me.\n",
      "\n",
      "Best regards,  \n",
      "[Your Name]\n",
      "\n",
      "---\n",
      "\n",
      "Would you like me to send this email for you? If so, please provide your boss’s email address.\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\"}]}, config)\n",
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f09fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some good practices for writing emails?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some good practices for writing effective emails:\n",
      "\n",
      "1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what to expect.\n",
      "\n",
      "2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\n",
      "\n",
      "3. **Be Concise and Direct:** Get to the point quickly. Use short paragraphs and avoid unnecessary details.\n",
      "\n",
      "4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it is free of errors.\n",
      "\n",
      "5. **Be Polite and Professional:** Use courteous language and maintain a professional tone, even if the email is informal.\n",
      "\n",
      "6. **Structure Your Email:** Use paragraphs, bullet points, or numbered lists to organize information clearly.\n",
      "\n",
      "7. **State Your Purpose Early:** Let the recipient know why you are writing within the first few sentences.\n",
      "\n",
      "8. **Include a Call to Action:** If you need a response or action, state it clearly.\n",
      "\n",
      "9. **Sign Off Properly:** End with a polite closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\n",
      "\n",
      "10. **Use a Professional Signature:** Include your contact information and job title if appropriate.\n",
      "\n",
      "11. **Be Mindful of Tone:** Avoid using all caps (which can seem like shouting) and be careful with humor or sarcasm, as it can be misinterpreted.\n",
      "\n",
      "12. **Reply Promptly:** Respond to emails in a timely manner, ideally within 24 hours.\n",
      "\n",
      "Would you like tips for a specific type of email (e.g., business, networking, follow-up)?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! Here’s a concise and direct email response to your boss, confirming your interest in attending Interrupt, following lesson 3:\n",
      "\n",
      "---\n",
      "\n",
      "**Subject:** Confirmation: Attendance at Interrupt\n",
      "\n",
      "Hello [Boss’s Name],\n",
      "\n",
      "Thank you for the opportunity. I would like to confirm that I am interested in attending Interrupt.\n",
      "\n",
      "Please let me know if there are any next steps or additional information you need from me.\n",
      "\n",
      "Best regards,  \n",
      "[Your Name]\n",
      "\n",
      "---\n",
      "\n",
      "Would you like me to send this email for you? If so, please provide your boss’s email address.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like this, let's write the email to boss@company.ai\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  write_email (call_PCdl6VMUhchpwYMwFZsOkg1k)\n",
      " Call ID: call_PCdl6VMUhchpwYMwFZsOkg1k\n",
      "  Args:\n",
      "    to: boss@company.ai\n",
      "    subject: Confirmation: Attendance at Interrupt\n",
      "    content: Hello,\n",
      "\n",
      "Thank you for the opportunity. I would like to confirm that I am interested in attending Interrupt.\n",
      "\n",
      "Please let me know if there are any next steps or additional information you need from me.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_email\n",
      "\n",
      "Email sent to boss@company.ai with subject 'Confirmation: Attendance at Interrupt' and content: Hello,\n",
      "\n",
      "Thank you for the opportunity. I would like to confirm that I am interested in attending Interrupt.\n",
      "\n",
      "Please let me know if there are any next steps or additional information you need from me.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The email has been written and sent to boss@company.ai, confirming your interest in attending Interrupt. If you need to customize the message further or send another email, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I like this, let's write the email to boss@company.ai\"}]}, config)\n",
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae8a5d2-cf8a-4465-8d1b-96bb6c6276cf",
   "metadata": {},
   "source": [
    "#### Interrupts\n",
    "\n",
    "In LangGraph, we can also use [interrupts](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/) to stop graph execution at specific points.\n",
    "\n",
    "Often this is used to collect input from a user and continue execution with collected input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52c17b60-9474-49a5-b4a1-583b0dc8bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    user_feedback: str\n",
    "\n",
    "def step_1(state):\n",
    "    print(\"---Step 1---\")\n",
    "    pass\n",
    "\n",
    "def human_feedback(state):\n",
    "    print(\"---human_feedback---\")\n",
    "    feedback = interrupt(\"Please provide feedback:\")\n",
    "    return {\"user_feedback\": feedback}\n",
    "\n",
    "def step_3(state):\n",
    "    print(\"---Step 3---\")\n",
    "    pass\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "builder.add_edge(START, \"step_1\")\n",
    "builder.add_edge(\"step_1\", \"human_feedback\")\n",
    "builder.add_edge(\"human_feedback\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "# Set up memory\n",
    "memory = InMemorySaver()\n",
    "\n",
    "# Add\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c94cb7-067c-4bc5-be33-b615d8e5775e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028372b5-88ae-4f13-813d-22430a697f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "initial_input = {\"input\": \"hello world\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f142d467-7b4c-4a04-bad5-bf3fbe953b84",
   "metadata": {},
   "source": [
    "To resume from an interrupt, we can use [the `Command` object](https://langchain-ai.github.io/langgraph/how-tos/command/). \n",
    "\n",
    "We'll use it to resume the graph from the interrupted state, passing the value to return from the interrupt call to `resume`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90374d3-65a1-4658-82ee-a16cc2835cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the graph execution\n",
    "for event in graph.stream(\n",
    "    Command(resume=\"go to step 3!\"),\n",
    "    thread,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639a518",
   "metadata": {},
   "source": [
    "### Tracing\n",
    "\n",
    "When we are using LangChain or LangGraph, LangSmith logging [will work out of the box](https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph) with the following environment variables set:\n",
    "\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_API_KEY=\"<your-langsmith-api-key>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2a3e5",
   "metadata": {},
   "source": [
    "Here is the LangSmith trace from above agent execution:\n",
    "\n",
    "https://smith.langchain.com/public/6f77014f-d054-44ed-aa2c-8b06ceab689f/r\n",
    "\n",
    "We can see that the agent is able to continue the conversation from the previous state because we used a checkpointer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0269214",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "We can also deploy our graph using [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/). \n",
    "\n",
    "This creates a server [with an API](https://langchain-ai.github.io/langgraph/cloud/reference/api/api_ref.html) that we can use to interact with our graph and an interactive IDE, LangGraph [Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/).\n",
    "\n",
    "We simply need to ensure our project has [a structure](https://langchain-ai.github.io/langgraph/concepts/application_structure/) like this:\n",
    "\n",
    "```\n",
    "my-app/\n",
    "├── src/email_assistant # all project code lies within here\n",
    "│   └── langgraph101.py # code for constructing your graph\n",
    "├── .env # environment variables\n",
    "├── langgraph.json  # configuration file for LangGraph\n",
    "└── pyproject.toml # dependencies for your project\n",
    "```\n",
    "\n",
    "The `langgraph.json` file specifies the dependencies, graphs, environment variables, and other settings required to start a LangGraph server.\n",
    "\n",
    "To test this, let's deploy `langgraph_101.py`. We have it in our `langgraph.json` file in this repo:\n",
    "\n",
    "```\n",
    " \"langgraph101\": \"./src/email_assistant/langgraph_101.py:app\",\n",
    "```\n",
    "\n",
    "For LangGraph Platform, there are a range of [deployment options](https://langchain-ai.github.io/langgraph/tutorials/deployment/): \n",
    " \n",
    "* Local deployments can be started with `langgraph dev` from the root directory of the repo. Checkpoints are saved to the local filesystem.\n",
    "* There are also various [self-hosted options](https://langchain-ai.github.io/langgraph/tutorials/deployment/#other-deployment-options). \n",
    "* For hosted deployments, checkpoints are saved to Postgres using a postgres [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries). \n",
    "\n",
    "Test: \n",
    "```\n",
    "Draft a response to my boss (boss@company.ai) confirming that I want to attent Interrupt!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3644093",
   "metadata": {},
   "source": [
    "Here we can see a visualization of the graph as well as the graph state in Studio.\n",
    "\n",
    "![langgraph_studio](img/langgraph_studio.png)\n",
    "\n",
    "Also, you can see API docs for the local deployment here:\n",
    "\n",
    "http://127.0.0.1:2024/docs"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
